{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPvabVlcbibMBRhVODNXePg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christiandatascience/Dive-into-Deep-Learning/blob/main/Linear_Neural_Networks_for_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dive into Deep Learning\n",
        "\n",
        "https://d2l.ai/"
      ],
      "metadata": {
        "id": "h7iO8HJUQ-OK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redes neuronales lineales para regresión\n"
      ],
      "metadata": {
        "id": "diGuZgaKkIPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de preocuparnos por hacer que nuestras redes neuronales sean profundas, será útil implementar algunas redes neuronales poco profundas, para las cuales las entradas se conectan directamente a las salidas. Esto resultará importante por varias razones. En primer lugar, en lugar de distraernos con arquitecturas complicadas, podemos centrarnos en los conceptos básicos del entrenamiento de redes neuronales, incluida la parametrización de la capa de salida, el manejo de datos, la especificación de una función de pérdida y el entrenamiento del modelo. En segundo lugar, esta clase de redes superficiales comprende el conjunto de modelos lineales, que subsume muchos métodos clásicos para la predicción estadística, incluida la regresión lineal y softmax. Comprender estas herramientas clásicas es fundamental porque se usan ampliamente en muchos contextos y, a menudo, necesitaremos usarlas como puntos de referencia para justificar el uso de arquitecturas más sofisticadas. Este capítulo se centrará estrictamente en la regresión lineal y el capítulo siguiente ampliará nuestro repertorio de modelado mediante el desarrollo de redes neuronales lineales para la clasificación."
      ],
      "metadata": {
        "id": "tw8XzImzkXMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión lineal"
      ],
      "metadata": {
        "id": "TvEqpIWMkpI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los problemas de regresión aparecen siempre que queremos predecir un valor numérico. Los ejemplos comunes incluyen la predicción de precios (de viviendas, existencias, etc.), la predicción de la duración de la estadía (para pacientes en el hospital), la previsión de la demanda (para ventas minoristas), entre muchos otros. No todos los problemas de predicción son un problema de regresión clásico. Más adelante, presentaremos problemas de clasificación, donde el objetivo es predecir la pertenencia a un conjunto de categorías.\n",
        "\n",
        "Como ejemplo, supongamos que deseamos estimar los precios de las casas (en dólares) en función de su área (en pies cuadrados) y edad (en años). Para desarrollar un modelo para predecir los precios de las casas, necesitamos obtener datos que consisten en ventas, incluido el precio de venta, el área y la edad de cada casa. En la terminología del aprendizaje automático, el conjunto de datos se denomina conjunto de datos de entrenamiento o conjunto de entrenamiento, y cada fila (que contiene los datos correspondientes a una venta) se denomina ejemplo (o punto de datos, instancia, muestra). Lo que intentamos predecir (precio) se llama etiqueta (u objetivo). Las variables (edad y área) en las que se basan las predicciones se denominan características (o covariables)."
      ],
      "metadata": {
        "id": "fuwtdybjlpfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l\n",
        "!pip install matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install torch\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "OiLSap4-l5a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2AC6SKg3pdW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Lo esencial"
      ],
      "metadata": {
        "id": "SwJyIrIjk3Bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "La regresión lineal puede ser tanto la más simple como la más popular entre las herramientas estándar para abordar los problemas de regresión. Remontándose a los albores del siglo XIX (Gauss, 1809, Legendre, 1805), la regresión lineal fluye a partir de unos pocos supuestos simples. En primer lugar, suponemos que la relación entre las características $\\mathbf{x}$\n",
        " y objetivo $y$\n",
        " es aproximadamente lineal, es decir, que la media condicional\n",
        "\n",
        "$E[Y \\mid X=\\mathbf{x}]$\n",
        "\n",
        " puede expresarse como una suma ponderada de las características\n",
        ". Esta configuración permite que el valor objetivo aún se desvíe de su valor esperado debido al ruido de observación. A continuación, podemos imponer la suposición de que cualquier ruido de este tipo se comporta bien, siguiendo una distribución gaussiana. Normalmente, utilizaremos\n",
        " para indicar el número de ejemplos en nuestro conjunto de datos. Usamos superíndices para enumerar muestras y objetivos, y subíndices para indexar coordenadas. Más concretamente,\n",
        " denota el\n",
        "-ésima muestra y\n",
        " denota su\n",
        "-ésima coordenada."
      ],
      "metadata": {
        "id": "TwY-U5CinDUl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN5T7C_JkDFp"
      },
      "outputs": [],
      "source": []
    }
  ]
}